<!DOCTYPE html>
<html>
<head>
    <title>Wenpu Li(ÊùéÊñáÊú¥)</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: Roboto, 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          h1 {
              font-weight: 300;
              font-size: 2rem;
          }
          #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 40px;
          }
          #header-text-title {
              font-size: 17px;
          }
          #header-text-affiliation {
              font-size: 17px;
              margin-top: 10px;
          }
          #header-text-email {
            margin-top: 10px;
            font-size: 17px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-3 offset-sm-1">
                    <img src='imgs/liwenpu_portrait.jpg' class='img-fluid' id='portrait'>
                </div>

                <div class="col">
                  <div id='header-text-name'>
                      Wenpu Li(ÊùéÊñáÊú¥)
                  </div>                  
                  <div id='header-text-title'>
                        ü§î <h5 style="display: inline;"><b>Think Different</b></h5> üöÄ <h5 style="display: inline;"><b>Go Further</b></h5>
                  <!-- ü§î <p style="font-size: 20px;"><b>Think Different</b></p> üöÄ <p style="font-size: 20px;"><b>Go Further</b></p> -->
                  </div>
                </br>
                    <div id='header-text-title'>
                        üßëüèª‚Äçüî¨ Research Assistant, <a href="https://ethliup.github.io/">Computer Vision and Geometric Learning lab (CVGL) </a>
                    </div>
                    <div id='header-text-affiliation'>
                        üè¢ Westlake University, School of Engineering </br>
                        <a href="https://en-soe.westlake.edu.cn/OurSchool/program/programAI/">Department of Artificial Intelligence and Data Science (AI)</a></br>
                    </div>
                  <div id='header-text-title'>
                        üì≠ liwenpu (at) westlake (dot) edu (dot) cn
                  </div>
                  <div>
                    <a href="https://github.com/akawincent">[GitHub]</a>
                    <a href="https://scholar.google.com/citations?user=C0mNwPkAAAAJ&hl=en">[Google Scholar]</a>
                    <a href="https://www.zhihu.com/people/wincent-84">[Zhihu]</a>
                    <!-- <a href="https://twitter.com/vincesitzmann">[Twitter]</a> -->
                    <!-- <a href="https://sigmoid.social/@vsitzmann">[Mastodon]</a> -->
                    <!-- <a href="docs/cv_vincent_sitzmann.pdf">[Download CV]</a> -->
                  </div>

                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <h1>üëã Bio</h1>
                <p>
                    I am currently a Research Assistant at <a href="https://ethliup.github.io/">Computer Vision and Geometric Learning lab (CVGL) </a>
                    supervised by <a href="https://en.westlake.edu.cn/faculty/peidong-liu.html">Prof. Peidong Liu</a>.
                    I obtained bachelor degree of Information Engineering from Guangdong University of Technology in 2024.
                    Previously, I worked as a research intern in CVGL during my senior year, focusing on 3D reconstruction.
                    In the summer of 2023, I visited the University of Cambridge to study deep learning and computer vision.
                    Before that, under the supervision of <a href="https://english.gdut.edu.cn/info/1025/1101.htm">Prof. Wei Meng</a>,
                    I studied robotics and the application of computer vision in intelligent robots, such as VO/VIO/SLAM.
                    </br> </br>
                    My research interest lies in 3D vision and Robotics. 
                    I aim to construct a representation of the real world in computers that mirrors human visual perception, 
                    fully utilizing latent information in 2D images such as blur, optical flow, events, or camera poses. 
                    I believe if we can reconstruct 3D/4D scenes in real-time from a video and obatain more information such as mesh, surface normal, texture, material and scene flow,   
                    it will helps robots to think more like humans so that they know how to efficiently interact with the real world. 
                </p>


               <div class='vspace-top'>
                    <h1>üåü News</h1>
               </div>

               <div class='row vspace-top-news'>
                   <div class="col-sm-2 news-date">
                        <li>07/2024</li>
                   </div>
                   <div class="col">
                        ü•≥ <p style="color: red; display: inline;">Paper acceptation:</p> Our paper BeNeRF is accepted to ECCV 2024! Thanks to all collaborators!
                   </div>
                </div>

               <div class='row vspace-top-news'>
                   <div class="col-sm-2 news-date">
                        <li>06/2024</li>
                   </div>
                   <div class="col">
                        üßëüèª‚Äçüéì I have graduated with a B.Eng from Guangdong University of Technology and received the Outstanding Graduate Honor!
                   </div>
               </div>

               <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        <li>05/2024</li>
                    </div>
                    <div class="col">
                        üìú I have finished my bachelor's thesis and received the Outstanding Bachelor Thesis Award!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        <li>08/2023</li>
                    </div>
                    <div class="col">
                        üõ†Ô∏è Start my 1-year internship at <a href="https://ethliup.github.io/">Computer Vision and Geometric Learning lab (CVGL) </a> at Westlake University.
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        <li>07/2023</li>
                    </div>
                    <div class="col">
                        üìö Start my 1-month visiting to study computer vision at Homerton College, University of Cambridge.
                    </div>
                </div>

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        January 2021-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--		    	I published a <a href="https://github.com/vsitzmann/awesome-implicit-representations">-->
<!--                        reading list on neural implicit representations</a> on github that I give students to get started in this area, inspired by the awesome-computer-vision list with extra commentary &amp; notes. Check it out!-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        January 2021-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--		    I am now serving as an academic advisor to <a href="https://preferred.jp/en/news/pr20210113/">Preferred Networks, Inc</a>!-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        June 2020-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        I just graduated Stanford with my <a href="docs/self_supervised_scene_rep_learning_vsitzmann.pdf">-->
<!--                        thesis on Self-supervised Scene Representation Learning</a>. There's a few interesting thoughts in there - -->
<!--                        especially check out the introduction and conclusion!-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        March 2020-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        Our CVPR tutorial on Neural Rendering is on youtube, free to watch for everyone!-->
<!--                        Here's the <a href="https://www.youtube.com/watch?v=LCTYRqW-ne8">link to the morning session</a> - -->
<!--                        at 2:20:00, I'm giving an overview over Novel View Synthesis.-->
<!--                        Here's the <a href="https://www.youtube.com/watch?v=JlyGNvbGKB8">link to the afternoon session</a>.-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        November 2019-->
<!--                    </div>-->

<!--                    <div class="col">-->
<!--		    	Our paper "Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations" wins an honorable mention for "Outstanding New Directions" at NeurIPS 2019! Watch my talk <a href="https://slideslive.com/38921749/track-1-session-3">here</a>.-->
<!--                    </div>-->
<!--                </div>-->


<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        May 2019-->
<!--                    </div>-->

<!--                    <div class="col">-->
<!--                        I will join Prof. Noah Snavely's group at the Google NYC office over the summer and continue working-->
<!--                        on  deep learning for scene understanding and novel view synthesis.-->
<!--                    </div>-->
<!--                </div>-->


                <div class='vspace-top'>
                    <h1>üìñ Publications</h1>
                </div>

                <p> * denotes equal contribution or advising; &dagger; denotes corresponding author</p>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/benerf_pipeline.png' class='img-fluid' width="230" height="140" >
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            BeNeRF: Neural Radiance Fields from a Single Blurry Image and Event Stream
                        </div>
                        <div class='paper-desc'>
                            ECCV 2024
                        </div>
                        <div class='paper-authors'>
                            <b>Wenpu Li*</b>, Pian Wan*, Peng Wang*, Jinghang Li, Yi Zhou, Peidong Liu‚Ä†
                        </div>
                        <div>
                            <a href="https://akawincent.github.io/BeNeRF">[Project page]</a>
                            <a href="https://arxiv.org/abs/2407.02174v2">[Paper]</a>
                            <a href="https://github.com/WU-CVGL/BeNeRF">[Code]</a>
                            <!-- <a href="https://colab.research.google.com/drive/1PeL5oJ_eraLEdzTEVPLBwoM2pyv26WcU?usp=sharing">[Colab]</a> -->
                        </div>

                        <p> TL;DR: We explore the possibility of recovering the neural radiance fields and camera motion trajectory from a single blurry image</p>

                    </div>
                </div>

                <div class='vspace-top'>
                    <h1>ü§ñ Projects</h1>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/Robot.jpg' class='img-fluid' style="width: 90%; height: 88%;">
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Wheeled Robot Equipped with a Robotic Arm for Automatic Storage
                        </div>
                        <div class='paper-desc'>
                            Automatic Storage/Retrieval System at Robocup China open, 2021
                        </div>
                        <div class='paper-authors'>
                            Qingrui Zhu, <b>Wenpu Li</b>, Wenbin Zheng, Yong Zhang, Junyao Li
                        </div>                        
                        <div>
                            <!-- <a href="https://yilundu.github.io/wide_baseline/">[Project page]</a> -->
                            <!-- <a href="https://arxiv.org/abs/2407.02174v2">[Paper]</a> -->
                            <a href="https://github.com/akawincent/2021-robocup-AS-RS">[Code]</a>
                            <!-- <a href="https://colab.research.google.com/drive/1PeL5oJ_eraLEdzTEVPLBwoM2pyv26WcU?usp=sharing">[Colab]</a> -->
                        </div>
                        
                        <p> TL;DR: I developed programs for robot navigation and localization, object recognition, and control algorithms to finish automatic storage task.</p>

                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/drone.jpg' class='img-fluid' style="width: 90%; height: 88%;">
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Self-Localization UAV Leveraging Visual Odometry
                        </div>
                        <div class='paper-desc'>
                            Course Project, 2023
                        </div>
                        <div class='paper-authors'>
                            <b>Wenpu Li</b>, Guohua Zhang
                        </div>                        
                        <div>
                            <!-- <a href="https://yilundu.github.io/wide_baseline/">[Project page]</a> -->
                            <!-- <a href="https://arxiv.org/abs/2407.02174v2">[Paper]</a> -->
                            <a href="https://github.com/StarLab317/VIO-Framework-for-Copter">[Code for drone]</a>
                            <a href="https://github.com/akawincent/ZED-data-collector">[Code for ZED Camera]</a>
                            <a href="https://www.bilibili.com/video/BV1ux4y1o75J/?spm_id_from=333.999.0.0&vd_source=12e3449d762538513192f94a7582c3bd">[Video]</a>
                            <!-- <a href="https://colab.research.google.com/drive/1PeL5oJ_eraLEdzTEVPLBwoM2pyv26WcU?usp=sharing">[Colab]</a> -->
                        </div>
                        
                        <p  style="display: inline;"> 
                            TL;DR: Working with <a href="https://github.com/guohua-zhang">GuoHua Zhang</a> on deploying Intel T265 Camera and Visual Odometry for Localization of UAV.
                            I also used ZED Camera to collect dataset to evaluate the performance of 
                            <a href="https://github.com/raulmur/ORB_SLAM2">ORB-SLAM2</a> and 
                            <a href="https://github.com/JiatianWu/stereo-dso">Stereo-DSO</a>.
                        </p>

                    </div>
                </div>

                <div class='vspace-top'>
                    <h1>üó£Ô∏è Language</h1>
                </div>

                <ul>
                    <li>Chinese: Native Language</li>
                    <li>Japanese: Native Language</li>
                    <li>English: Intermediate Level</li>
                    <li>Cantonese: Entry Level</li>
                </ul>

                <div class='vspace-top'>
                    <h1>üèÖ Awards</h1>
                </div>

                <ul>
                    <li><b>National Bronze Medal</b> in Automatic Storage/Retrieval System at Robocup China open, 2021</li>
                    <li><b>National Second Prize</b> in Automatic Storage/Retrieval System at Robocup China open, 2022</li>
                    <li><b>National Second Prize</b> in iCAN Innovation Contest, 2022</li>
                    <li><b>National Third Prize</b> in Blue Bridge Cup, 2022</li>
                    <li><b>First Prize</b> in Contemporary Undergraduate Mathematical Contest in Modeling(Guangdong Division), 2022</li>
                    <li><b>Third Prize</b> in National Undergraduate Electronics Design Contest(Guangdong Division), 2021</li>
                    <li><b>Second Prize</b> in Excellent Student Scholarship, Guangdong University of Technology, 2023</li>
                    <li><b>Third Prize</b> in Fangzhi Scholarship, Guangdong University of Technology, 2021</li>
                </ul>

                <div class='vspace-top'>
                    <h1>üéÄ Acknowledgement</h1>

                    <p> Thanks to Wenyi Zhang for taking the portrait for my homepage.</p>

                </div>

            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
